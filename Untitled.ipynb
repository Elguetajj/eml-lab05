{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "induced-profile",
   "metadata": {},
   "source": [
    "# Polynomic regularized linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "streaming-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_cost(X, y, theta,lambd):\n",
    "    h = X @ theta\n",
    "    return ((h - y) ** 2).sum() / (2*len(X)) + (lambd/(2*X.shape[0])) * np.sum(theta**2)\n",
    "\n",
    "\n",
    "def linear_cost_gradient(X, y, theta, lambd):\n",
    "    h = X @ theta\n",
    "    return (((h - y).T @ X).T )+ (theta * lambd)/ (2*len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dangerous-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X,degree):\n",
    "    m,n = X.shape\n",
    "    X_transformed = np.ones(m).reshape(m,1)\n",
    "    for i in range(n):\n",
    "        for j in range(1,degree+1):\n",
    "            X_transformed = np.hstack(\n",
    "                (\n",
    "                    X_transformed,\n",
    "                    (np.copy(X[:,i])**j).reshape(m,1)    \n",
    "                )\n",
    "            )  \n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "damaged-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    X,\n",
    "    y,\n",
    "    cost_function,\n",
    "    cost_function_gradient,\n",
    "    theta=0,\n",
    "    degree=1,\n",
    "    learning_rate=0.01,\n",
    "    threshold=0.001,\n",
    "    max_iter=1000,\n",
    "    lambd=3\n",
    "):\n",
    "    \n",
    "    if (degree>1):\n",
    "        X = transform(X,degree)\n",
    "       \n",
    "    m,n = X.shape\n",
    "    \n",
    "    if(theta==0):\n",
    "        theta= np.random.rand(n,1)\n",
    "    \n",
    "    iteration = 0\n",
    "    costs=[]\n",
    "\n",
    "    while np.linalg.norm(cost_function_gradient(X,y,theta,lambd)) > threshold and iteration < max_iter:\n",
    "        iteration = iteration+1\n",
    "        theta = theta-(learning_rate*cost_function_gradient(X,y,theta,lambd))\n",
    "        costs.append(cost_function(X,y,theta,lambd))\n",
    "                \n",
    "    return theta,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recorded-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,thetas,degree):\n",
    "    X = transform(np.copy(X),degree)\n",
    "    y_pred = X @ thetas\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rental-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(predicted,actual):\n",
    "    return 1 - (np.sum((actual-predicted)**2)/(np.sum((actual-np.mean(actual))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artistic-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   nan,    nan,    nan, ...,    nan,    nan,    nan],\n",
       "       [  1.  , 337.  , 118.  , ...,   9.65,   1.  ,   0.92],\n",
       "       [  2.  , 324.  , 107.  , ...,   8.87,   1.  ,   0.76],\n",
       "       ...,\n",
       "       [398.  , 330.  , 116.  , ...,   9.45,   1.  ,   0.91],\n",
       "       [399.  , 312.  , 103.  , ...,   8.78,   0.  ,   0.67],\n",
       "       [400.  , 333.  , 117.  , ...,   9.66,   1.  ,   0.95]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('./Admission_Predict.csv', delimiter=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "moved-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.copy(data[1:,:-1])\n",
    "y = np.copy(data[1:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "imposed-typing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  , 337.  , 118.  , ...,   4.5 ,   9.65,   1.  ],\n",
       "       [  2.  , 324.  , 107.  , ...,   4.5 ,   8.87,   1.  ],\n",
       "       [  3.  , 316.  , 104.  , ...,   3.5 ,   8.  ,   1.  ],\n",
       "       ...,\n",
       "       [398.  , 330.  , 116.  , ...,   4.5 ,   9.45,   1.  ],\n",
       "       [399.  , 312.  , 103.  , ...,   4.  ,   8.78,   0.  ],\n",
       "       [400.  , 333.  , 117.  , ...,   4.  ,   9.66,   1.  ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dynamic-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92, 0.76, 0.72, 0.8 , 0.65, 0.9 , 0.75, 0.68, 0.5 , 0.45, 0.52,\n",
       "       0.84, 0.78, 0.62, 0.61, 0.54, 0.66, 0.65, 0.63, 0.62, 0.64, 0.7 ,\n",
       "       0.94, 0.95, 0.97, 0.94, 0.76, 0.44, 0.46, 0.54, 0.65, 0.74, 0.91,\n",
       "       0.9 , 0.94, 0.88, 0.64, 0.58, 0.52, 0.48, 0.46, 0.49, 0.53, 0.87,\n",
       "       0.91, 0.88, 0.86, 0.89, 0.82, 0.78, 0.76, 0.56, 0.78, 0.72, 0.7 ,\n",
       "       0.64, 0.64, 0.46, 0.36, 0.42, 0.48, 0.47, 0.54, 0.56, 0.52, 0.55,\n",
       "       0.61, 0.57, 0.68, 0.78, 0.94, 0.96, 0.93, 0.84, 0.74, 0.72, 0.74,\n",
       "       0.64, 0.44, 0.46, 0.5 , 0.96, 0.92, 0.92, 0.94, 0.76, 0.72, 0.66,\n",
       "       0.64, 0.74, 0.64, 0.38, 0.34, 0.44, 0.36, 0.42, 0.48, 0.86, 0.9 ,\n",
       "       0.79, 0.71, 0.64, 0.62, 0.57, 0.74, 0.69, 0.87, 0.91, 0.93, 0.68,\n",
       "       0.61, 0.69, 0.62, 0.72, 0.59, 0.66, 0.56, 0.45, 0.47, 0.71, 0.94,\n",
       "       0.94, 0.57, 0.61, 0.57, 0.64, 0.85, 0.78, 0.84, 0.92, 0.96, 0.77,\n",
       "       0.71, 0.79, 0.89, 0.82, 0.76, 0.71, 0.8 , 0.78, 0.84, 0.9 , 0.92,\n",
       "       0.97, 0.8 , 0.81, 0.75, 0.83, 0.96, 0.79, 0.93, 0.94, 0.86, 0.79,\n",
       "       0.8 , 0.77, 0.7 , 0.65, 0.61, 0.52, 0.57, 0.53, 0.67, 0.68, 0.81,\n",
       "       0.78, 0.65, 0.64, 0.64, 0.65, 0.68, 0.89, 0.86, 0.89, 0.87, 0.85,\n",
       "       0.9 , 0.82, 0.72, 0.73, 0.71, 0.71, 0.68, 0.75, 0.72, 0.89, 0.84,\n",
       "       0.93, 0.93, 0.88, 0.9 , 0.87, 0.86, 0.94, 0.77, 0.78, 0.73, 0.73,\n",
       "       0.7 , 0.72, 0.73, 0.72, 0.97, 0.97, 0.69, 0.57, 0.63, 0.66, 0.64,\n",
       "       0.68, 0.79, 0.82, 0.95, 0.96, 0.94, 0.93, 0.91, 0.85, 0.84, 0.74,\n",
       "       0.76, 0.75, 0.76, 0.71, 0.67, 0.61, 0.63, 0.64, 0.71, 0.82, 0.73,\n",
       "       0.74, 0.69, 0.64, 0.91, 0.88, 0.85, 0.86, 0.7 , 0.59, 0.6 , 0.65,\n",
       "       0.7 , 0.76, 0.63, 0.81, 0.72, 0.71, 0.8 , 0.77, 0.74, 0.7 , 0.71,\n",
       "       0.93, 0.85, 0.79, 0.76, 0.78, 0.77, 0.9 , 0.87, 0.71, 0.7 , 0.7 ,\n",
       "       0.75, 0.71, 0.72, 0.73, 0.83, 0.77, 0.72, 0.54, 0.49, 0.52, 0.58,\n",
       "       0.78, 0.89, 0.7 , 0.66, 0.67, 0.68, 0.8 , 0.81, 0.8 , 0.94, 0.93,\n",
       "       0.92, 0.89, 0.82, 0.79, 0.58, 0.56, 0.56, 0.64, 0.61, 0.68, 0.76,\n",
       "       0.86, 0.9 , 0.71, 0.62, 0.66, 0.65, 0.73, 0.62, 0.74, 0.79, 0.8 ,\n",
       "       0.69, 0.7 , 0.76, 0.84, 0.78, 0.67, 0.66, 0.65, 0.54, 0.58, 0.79,\n",
       "       0.8 , 0.75, 0.73, 0.72, 0.62, 0.67, 0.81, 0.63, 0.69, 0.8 , 0.43,\n",
       "       0.8 , 0.73, 0.75, 0.71, 0.73, 0.83, 0.72, 0.94, 0.81, 0.81, 0.75,\n",
       "       0.79, 0.58, 0.59, 0.47, 0.49, 0.47, 0.42, 0.57, 0.62, 0.74, 0.73,\n",
       "       0.64, 0.63, 0.59, 0.73, 0.79, 0.68, 0.7 , 0.81, 0.85, 0.93, 0.91,\n",
       "       0.69, 0.77, 0.86, 0.74, 0.57, 0.51, 0.67, 0.72, 0.89, 0.95, 0.79,\n",
       "       0.39, 0.38, 0.34, 0.47, 0.56, 0.71, 0.78, 0.73, 0.82, 0.62, 0.96,\n",
       "       0.96, 0.46, 0.53, 0.49, 0.76, 0.64, 0.71, 0.84, 0.77, 0.89, 0.82,\n",
       "       0.84, 0.91, 0.67, 0.95])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "apart-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\elgue\\eml-lab05\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:47: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "<ipython-input-23-fec9fc81b05f>:3: RuntimeWarning: overflow encountered in square\n",
      "  return ((h - y) ** 2).sum() / (2*len(X)) + (lambd/(2*X.shape[0])) * np.sum(theta**2)\n",
      "<ipython-input-23-fec9fc81b05f>:8: RuntimeWarning: overflow encountered in matmul\n",
      "  return (((h - y).T @ X).T )+ (theta * lambd)/ (2*len(X))\n"
     ]
    }
   ],
   "source": [
    "theta, costs = gradient_descent(X,y,linear_cost,linear_cost_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distant-bicycle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "removable-tracker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improved-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(results[0][1])\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Cost')\n",
    "# plt.title('Cost Function')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
